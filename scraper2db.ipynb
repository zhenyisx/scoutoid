{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIJsJSvtPMMn8SlNWGNsCX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhenyisx/scoutoid/blob/main/scraper2db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To scrape website and populate to database (csv file) on Google Drive. The files can then be uploaded to Goolge Storage for clients (i.e., stremlit) to consume."
      ],
      "metadata": {
        "id": "Z46myB-0fZNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Function Definitions"
      ],
      "metadata": {
        "id": "Mh_peAjDPRXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import date, datetime, timedelta\n",
        "import re\n",
        "\n",
        "from google.colab import  drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# TODO\n",
        "# - home team and away team are reverse in current table\n",
        "# - team should add city and state"
      ],
      "metadata": {
        "id": "_dEawkCOfhSz",
        "outputId": "2c059348-9351-4b7d-b257-c0a7a4214c5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores_from_soup(maxpreps_day_soup, this_day):\n",
        "  \"\"\"to get scores of games in one day.\n",
        "\n",
        "  Args:\n",
        "      maxpreps_day_soup (soup): a soup parsed from MaxPreps HTML by BS.\n",
        "      this_day (str): the date.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # create dateframe of game schedules and scores\n",
        "  schedule_df = pd.DataFrame({'Date': pd.Series(dtype='datetime64[ns]'),\n",
        "                    'Home Team': pd.Series(dtype='str'),\n",
        "                    'Home Score': pd.Series(dtype='int'),\n",
        "                    'Away Team': pd.Series(dtype='str'),\n",
        "                    'Away Score': pd.Series(dtype='int')})\n",
        "\n",
        "  # populate the datafrme by analyzing the soup (MaxPreps specific)\n",
        "  # to use ChromeDev Tool to get the following rules of find \n",
        "  matches = maxpreps_day_soup.find('div', {'class': 'contests'})\n",
        "\n",
        "  for m in matches.find_all('ul', {'class': 'teams'}):\n",
        "    raw_record = m.find_all(\"li\")\n",
        "\n",
        "    # home score\n",
        "    try:\n",
        "      home_score = int(raw_record[0].find('div', {'class': 'score'}).text.strip())\n",
        "    except ValueError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        home_score = -1\n",
        "    except AttributeError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        home_score = -1\n",
        "    # print(home_score)\n",
        "\n",
        "    # home name\n",
        "    home_name = raw_record[0].find('div', {'class': 'name'}).text.strip()\n",
        "    # print(home_name)\n",
        "\n",
        "    # away score\n",
        "    try:\n",
        "      away_score = int(raw_record[1].find('div', {'class': 'score'}).text.strip())\n",
        "    except ValueError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        away_score = -1\n",
        "    except AttributeError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        away_score = -1\n",
        "    # print(away_score)\n",
        "\n",
        "    # away name\n",
        "    away_name = raw_record[1].find('div', {'class': 'name'}).text.strip()\n",
        "    # print(away_name)\n",
        "\n",
        "    m_result = {'Date':this_day, 'Home Team':home_name, 'Home Score':home_score, \n",
        "                'Away Team':away_name, 'Away Score':away_score}\n",
        "    schedule_df = schedule_df.append(m_result, ignore_index=True)\n",
        "\n",
        "  schedule_df = schedule_df.drop_duplicates(keep='last')\n",
        "\n",
        "  return schedule_df\n",
        "  \n",
        "\n",
        "def get_scores_from_maxpreps_for_one_day(today):\n",
        "  \"\"\"to get scores of games from MaxPreps in one day.\n",
        "\n",
        "  Example:\n",
        "  df = get_scores_from_maxpreps_for_one_day(\"12/1/2022\")\n",
        "  print(df)\n",
        "\n",
        "  Args:\n",
        "      this_day (str): the date str in '%m/%d/%Y' format.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "  # maxpreps's homepage\n",
        "  maxpreps_url = 'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today)  # please change the date if needed\n",
        "\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  maxpreps_response = requests.get(maxpreps_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  maxpreps_soup = BeautifulSoup(maxpreps_response.text, 'html.parser')\n",
        "\n",
        "  # Title of the parsed page\n",
        "  print(maxpreps_soup.title.text)\n",
        "\n",
        "  # check if the dates match\n",
        "  try:\n",
        "    content_date = datetime.strptime(maxpreps_soup.title.text.split('|')[1].strip().split()[0], '%m/%d/%Y')\n",
        "    # another way to find the content current date\n",
        "    # content = maxpreps_soup.find('div', {'class': 'calendar'}).find('ol', {'class': 'week'}).find('a', {'class': 'btn btn-default active'})\n",
        "    # content_date = datetime.strptime(content.text, '%m/%d/%Y'))\n",
        "    if content_date == datetime.strptime(today, '%m/%d/%Y'):\n",
        "      print('Found Games for {}'.format(content_date))\n",
        "      scores_df = get_scores_from_soup(maxpreps_soup, content_date)\n",
        "      return scores_df\n",
        "    else:\n",
        "      print('No Games found for {}'.format(today))\n",
        "  except TypeError:\n",
        "    print('No Games found for {}'.format(today))\n",
        "  except ValueError:\n",
        "    print('No Games found for {}'.format(today))\n",
        "\n",
        "\n",
        "def get_scores_from_maxpreps_for_range(start_date, end_date):\n",
        "  \"\"\"to get scores of games from MaxPreps in a date range.\n",
        "\n",
        "  Example:\n",
        "  start_date = date(2022, 11, 10)\n",
        "  end_date = date(2023, 2, 10)\n",
        "  scores = get_scores_from_maxpreps_for_range(start_date, end_date)\n",
        "\n",
        "  Args:\n",
        "      start_date (date): the start date.\n",
        "      end_date (date): the end date.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "  def daterange(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "  dfs = []\n",
        "  for single_date in daterange(start_date, end_date):\n",
        "      today = single_date.strftime(\"%m/%d/%Y\")\n",
        "      scores_df = get_scores_from_maxpreps_for_one_day(today)\n",
        "      if scores_df is None:\n",
        "        print('No games found on {}'.format(today))\n",
        "      else:\n",
        "        print('Found {} games for {}'.format(len(scores_df), today))\n",
        "      dfs.append(scores_df)\n",
        "\n",
        "  # see pd.concat documentation for more info\n",
        "  concat_scores_df = pd.concat(dfs)\n",
        "  concat_scores_df = concat_scores_df.drop_duplicates(keep='last')\n",
        "  return concat_scores_df\n"
      ],
      "metadata": {
        "id": "XG32BV0UzUii"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rankings_from_scores(schedule_df):\n",
        "  \"\"\"to ranking statistics of teams from the schedules and scores\n",
        "\n",
        "  Example:\n",
        "  df = get_scores_from_maxpreps_for_one_day(\"12/1/2022\")\n",
        "  print(df)\n",
        "\n",
        "  Args:\n",
        "      schedule_df (dataframe): the scores dataframe.\n",
        "\n",
        "  Returns:\n",
        "      ranking_df (dataframe): the dataframe of ranking statistics.\n",
        "\n",
        "  \"\"\"\n",
        "  teams = list(set(list(schedule_df[\"Home Team\"].unique()) + \n",
        "                   list(schedule_df[\"Away Team\"].unique())))\n",
        "\n",
        "  # initialize the ranking dataframe\n",
        "  ranking_df = pd.DataFrame({\n",
        "                    'Team': pd.Series(dtype='str'),\n",
        "                    'Total Points': pd.Series(dtype='int'),\n",
        "                    'Total Games': pd.Series(dtype='int'),\n",
        "                    'Total Wins': pd.Series(dtype='int'),\n",
        "                    'Total Losses': pd.Series(dtype='int'),\n",
        "                    'Total Ties': pd.Series(dtype='int'),\n",
        "                    'PPG': pd.Series(dtype='float'),})\n",
        "\n",
        "  for t in teams:\n",
        "    t_result = {'Team':t, 'Total Points': 0,\n",
        "                    'Total Games': 0,\n",
        "                    'Total Wins': 0,\n",
        "                    'Total Losses': 0,\n",
        "                    'Total Ties': 0,\n",
        "                    'PPG':0}\n",
        "    ranking_df = ranking_df.append(t_result, ignore_index=True)\n",
        "\n",
        "  # populate ranking dataframe based on schedule\n",
        "  for index,row in schedule_df.iterrows():\n",
        "    home_team = row['Home Team']\n",
        "    away_team = row['Away Team']\n",
        "    home_score = row['Home Score']\n",
        "    away_score = row['Away Score']\n",
        "\n",
        "    ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Games'] += 1\n",
        "    ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Games'] += 1\n",
        "\n",
        "    if home_score > away_score: # home win  \n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Wins'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Points'] += 3\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Losses'] += 1\n",
        "    elif home_score < away_score: # away win\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Wins'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Points'] += 3\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Losses'] += 1\n",
        "    elif home_score == away_score: # tie\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Ties'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Ties'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Points'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Points'] += 1\n",
        "\n",
        "  ranking_df['PPG'] = ranking_df['Total Points'] / ranking_df['Total Games']\n",
        "\n",
        "  ranking_df = ranking_df.sort_values(by=['PPG', 'Total Points'], \n",
        "                                      ascending=False)\n",
        "  ranking_df = ranking_df.drop_duplicates(keep='last')\n",
        "  return ranking_df\n"
      ],
      "metadata": {
        "id": "nksiVfx8w3O6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Script"
      ],
      "metadata": {
        "id": "qGqG335tPH0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demo\n",
        "df = get_scores_from_maxpreps_for_one_day(\"2/21/2023\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "vVlhCgezUxXt",
        "outputId": "fec1c565-6a8e-463a-d7ff-5d289ecdf832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/21/2023 Results | MaxPreps\r\n",
            "\n",
            "Found Games for 2023-02-21 00:00:00\n",
            "        Date Home Team  Home Score          Away Team  Away Score\n",
            "0 2023-02-21   Branham           1  Sacred Heart Prep           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all scores\n",
        "# please note game info of previous seasons/years are not accessible,\n",
        "# only current season is accessible.\n",
        "\n",
        "# load historical data\n",
        "# scores.csv was generated between 11/10/2022 and 2/1/2023\n",
        "hist_scores = pd.read_csv('/drive/My Drive/scores.csv')\n",
        "\n",
        "start_date = date(2023, 2, 1)\n",
        "end_date = date(2023, 3, 12)\n",
        "new_scores = get_scores_from_maxpreps_for_range(start_date, end_date)\n",
        "\n",
        "scores = pd.concat([hist_scores, new_scores])\n",
        "scores['Date'] = pd.to_datetime(scores['Date'])\n",
        "scores = scores.drop_duplicates(keep='last')\n",
        "scores.to_csv('/drive/My Drive/scores_2223_03112023.csv', index=False)"
      ],
      "metadata": {
        "id": "GuJkF8RrOaut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all rankings\n",
        "rankings = get_rankings_from_scores(scores)\n",
        "rankings.to_csv('/drive/My Drive/rankings_2223_03112023.csv', index=False)"
      ],
      "metadata": {
        "id": "sah_im9Sr2a5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Method"
      ],
      "metadata": {
        "id": "fydMxgKcV-ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new dataset for the scores and rankings\n",
        "# one shot (not combining)\n",
        "\n",
        "# combine with historical data"
      ],
      "metadata": {
        "id": "SDDWC6P9WClY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test of Script"
      ],
      "metadata": {
        "id": "IR1OlpxXM9_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### analyze game summary page"
      ],
      "metadata": {
        "id": "SLbKiODcAHzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_date =  date(2023, 2, 28)\n",
        "today = single_date.strftime(\"%m/%d/%Y\")\n",
        "\n",
        "# maxpreps's homepage\n",
        "maxpreps_url = 'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today)  # please change the date if needed\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "maxpreps_response = requests.get(maxpreps_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "maxpreps_soup = BeautifulSoup(maxpreps_response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "biTur2QgM7iz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find all the div (each div is a game) and print a link in each div\n",
        "for gamediv in maxpreps_soup.find_all(\"div\", {\"class\": \"contest-box-item\"}):#maxpreps_soup.findAll('a', {'class': 'c-c'}):\n",
        "    try:\n",
        "        # print(gamediv['href'])\n",
        "        # print(gamediv)\n",
        "        print(gamediv.find('a')['href'])\n",
        "    except KeyError:\n",
        "        print(\"no href\")\n",
        "        pass"
      ],
      "metadata": {
        "id": "jSV0LmfhSSF7",
        "outputId": "3e29eafa-9391-4bf8-cc90-d2c143408774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/colfax-vs-wilcox.htm?c=wsIDk6mPmkGfVLtp2BYtQg\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/presentation-vs-windsor.htm?c=kWgQYflpLk60D3-K60z9pA\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/del-oro-vs-mountain-view.htm?c=u01OUaFD1Umm2B5lv1N1bQ\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/branson-vs-st-ignatius-college-preparatory.htm?c=GSINjvyoPUehsRihjuAQLQ\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/piedmont-vs-sequoia.htm?c=F0HUgZBKKUm86x_KpZobug\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/clovis-north-vs-menlo-atherton.htm?c=jyXzDj2NR0aSJjwt6hSIsA\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/hamilton-vs-hollister.htm?c=1FE4ty4pnE-97nJfzaM-MA\n",
            "https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/saint-francis-vs-san-ramon-valley.htm?c=lOgYvZwX6kWDaCzpHU4rWg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find  details of one game using the link\n",
        "# game_detail_page = \"https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/presentation-vs-windsor.htm?c=kWgQYflpLk60D3-K60z9pA\" # simple example\n",
        "game_detail_page = \"https://www.maxpreps.com/games/2-22-2023/girls-soccer-winter-22-23/menlo-atherton-vs-mountain-view.htm?c=JPH2i5aDH0yYvdk1bipRfg\" # complete example\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "gamedetail_response = requests.get(game_detail_page, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "gamedetail_soup = BeautifulSoup(gamedetail_response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "QmTxCOCFCYp0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Classes of each table:')\n",
        "# for table in gamedetail_soup.find_all('table'):\n",
        "#     print(table.get('class'))\n",
        "\n",
        "def get_text(ele):\n",
        "  return ele.text if ele is not None else None\n",
        "\n",
        "\n",
        "def find_city(team_name, summary):\n",
        "  res = re.search(r'{} \\((.*?)\\)'.format(team_name), summary, re.IGNORECASE)\n",
        "  if res:\n",
        "      return res.group(1)\n",
        "\n",
        "# find summary\n",
        "game_summary = get_text(gamedetail_soup.find('p', attrs={'class' : 'contest-description'}))\n",
        "print(game_summary)\n",
        "\n",
        "# analyze target table\n",
        "table = gamedetail_soup.find('table', class_='mx-grid boxscore d-b-s post soccer')\n",
        "# print(table)\n",
        "\n",
        "# for r in table.findChildren(['th', 'tr']):\n",
        "#   print(r)\n",
        "\n",
        "for r in table.tbody.find_all('tr'):\n",
        "  # find team name\n",
        "  team_name = get_text(r.find('th', class_='team first'))\n",
        "  print(find_city(team_name, game_summary))\n",
        "  first_half_score = get_text(r.find('td', class_='firsthalf score dw'))\n",
        "  second_half_score = get_text(r.find('td', class_='secondhalf score dw'))\n",
        "  total_score = get_text(r.find('td', class_='score total score'))\n",
        "  shootout_score = get_text(r.find('td', class_='shootout stat tiebreaker dw'))\n",
        "  is_winner = get_text(r.find('td', class_='winner last'))\n",
        "\n",
        "  print(team_name)\n",
        "  print(first_half_score)\n",
        "  print(second_half_score)\n",
        "  print(total_score)\n",
        "  print(shootout_score)\n",
        "  print(is_winner)\n",
        "\n",
        "\n",
        "# need to record howm/away information in one row"
      ],
      "metadata": {
        "id": "iDTaFPw_SuoD",
        "outputId": "a40d3a99-a15d-45f4-c0fc-d3edd1d666f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Menlo-Atherton (Atherton, CA) varsity soccer team won Wednesday's home playoff game against Mountain View (CA) in a shootout after a score of 0-0.\n",
            "CA\n",
            "Mountain View\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "\n",
            "Atherton, CA\n",
            "Menlo-Atherton\n",
            "0\n",
            "0\n",
            "0\n",
            "4\n",
            "✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "game_url = 'https://www.maxpreps.com/games/2-22-2023/girls-soccer-winter-22-23/menlo-atherton-vs-mountain-view.htm?c=JPH2i5aDH0yYvdk1bipRfg'  # please change the date if needed\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "game_response = requests.get(game_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "game_soup = BeautifulSoup(game_response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "1gDIMhRaTd9y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(game_soup)"
      ],
      "metadata": {
        "id": "_fDZ6yq0Y7ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "for d in game_soup.find_all('p', attrs={'class' : 'contest-description'}): # {'class': 'contest-description'}\n",
        "    try:\n",
        "        print(d.text)\n",
        "        addr_search = re.search(r'Menlo-Atherton \\((.*?)\\)', d.text, re.IGNORECASE)\n",
        "\n",
        "        if addr_search:\n",
        "            addr = addr_search.group(1)\n",
        "            print(addr)\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "metadata": {
        "id": "QXZ1M3J6TvlQ",
        "outputId": "b357f7b9-6a03-45f4-9aa7-795b89e70171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Menlo-Atherton (Atherton, CA) varsity soccer team won Wednesday's home playoff game against Mountain View (CA) in a shootout after a score of 0-0.\n",
            "Atherton, CA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in game_soup.find_all('th', attrs={'class' : 'team first'}): # {'class': 'contest-description'}\n",
        "    try:\n",
        "        print(t.text)\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "metadata": {
        "id": "x3tRHgRibQTz",
        "outputId": "3053b3e2-6848-4772-b7f9-ec0383a753f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mountain View\n",
            "Menlo-Atherton\n",
            "Mountain View\n",
            "Menlo-Atherton\n",
            "Mountain View\n",
            "Menlo-Atherton\n"
          ]
        }
      ]
    }
  ]
}