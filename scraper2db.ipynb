{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNkWO5EioTFlUDPjEH3NC7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhenyisx/scoutoid/blob/main/scraper2db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To scrape website and populate to database (csv file) on Google Drive. The files can then be uploaded to Goolge Storage for clients (i.e., stremlit) to consume."
      ],
      "metadata": {
        "id": "Z46myB-0fZNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Function Definitions"
      ],
      "metadata": {
        "id": "Mh_peAjDPRXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import date, datetime, timedelta\n",
        "import re\n",
        "\n",
        "from google.colab import  drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# TODO\n",
        "# - home team and away team are reverse in current table\n",
        "# - team should add city and state"
      ],
      "metadata": {
        "id": "_dEawkCOfhSz",
        "outputId": "47c0190c-d1d4-406e-90c7-e0a6829fd98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores_from_soup(maxpreps_day_soup, this_day):\n",
        "  \"\"\"to get scores of games in one day.\n",
        "\n",
        "  Args:\n",
        "      maxpreps_day_soup (soup): a soup parsed from MaxPreps HTML by BS.\n",
        "      this_day (str): the date.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # create dateframe of game schedules and scores\n",
        "  schedule_df = pd.DataFrame({'Date': pd.Series(dtype='datetime64[ns]'),\n",
        "                    'Home Team': pd.Series(dtype='str'),\n",
        "                    'Home Score': pd.Series(dtype='int'),\n",
        "                    'Away Team': pd.Series(dtype='str'),\n",
        "                    'Away Score': pd.Series(dtype='int')})\n",
        "\n",
        "  # populate the datafrme by analyzing the soup (MaxPreps specific)\n",
        "  # to use ChromeDev Tool to get the following rules of find\n",
        "  matches = maxpreps_day_soup.find('div', {'class': 'contests'})\n",
        "\n",
        "  for m in matches.find_all('ul', {'class': 'teams'}):\n",
        "    raw_record = m.find_all(\"li\")\n",
        "\n",
        "    # home score\n",
        "    try:\n",
        "      home_score = int(raw_record[0].find('div', {'class': 'score'}).text.strip())\n",
        "    except ValueError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        home_score = -1\n",
        "    except AttributeError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        home_score = -1\n",
        "    # print(home_score)\n",
        "\n",
        "    # home name\n",
        "    home_name = raw_record[0].find('div', {'class': 'name'}).text.strip()\n",
        "    # print(home_name)\n",
        "\n",
        "    # away score\n",
        "    try:\n",
        "      away_score = int(raw_record[1].find('div', {'class': 'score'}).text.strip())\n",
        "    except ValueError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        away_score = -1\n",
        "    except AttributeError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        away_score = -1\n",
        "    # print(away_score)\n",
        "\n",
        "    # away name\n",
        "    away_name = raw_record[1].find('div', {'class': 'name'}).text.strip()\n",
        "    # print(away_name)\n",
        "\n",
        "    m_result = {'Date':this_day, 'Home Team':home_name, 'Home Score':home_score,\n",
        "                'Away Team':away_name, 'Away Score':away_score}\n",
        "    # schedule_df = schedule_df.append(m_result, ignore_index=True)\n",
        "    schedule_df = pd.concat([schedule_df, pd.DataFrame([m_result])], ignore_index=True)\n",
        "\n",
        "\n",
        "  schedule_df = schedule_df.drop_duplicates(keep='last')\n",
        "\n",
        "  return schedule_df\n",
        "\n",
        "\n",
        "def get_scores_from_maxpreps_for_one_day(today):\n",
        "  \"\"\"to get scores of games from MaxPreps in one day.\n",
        "\n",
        "  Example:\n",
        "  df = get_scores_from_maxpreps_for_one_day(\"12/1/2022\")\n",
        "  print(df)\n",
        "\n",
        "  Args:\n",
        "      this_day (str): the date str in '%m/%d/%Y' format.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "  # maxpreps's homepage\n",
        "  maxpreps_url = 'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today)  # please change the date if needed\n",
        "\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  maxpreps_response = requests.get(maxpreps_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  maxpreps_soup = BeautifulSoup(maxpreps_response.text, 'html.parser')\n",
        "\n",
        "  # Title of the parsed page\n",
        "  print(maxpreps_soup.title.text)\n",
        "\n",
        "  # check if the dates match\n",
        "  try:\n",
        "    content_date = datetime.strptime(maxpreps_soup.title.text.split('|')[1].strip().split()[0], '%m/%d/%Y')\n",
        "    # another way to find the content current date\n",
        "    # content = maxpreps_soup.find('div', {'class': 'calendar'}).find('ol', {'class': 'week'}).find('a', {'class': 'btn btn-default active'})\n",
        "    # content_date = datetime.strptime(content.text, '%m/%d/%Y'))\n",
        "    if content_date == datetime.strptime(today, '%m/%d/%Y'):\n",
        "      print('Found Games for {}'.format(content_date))\n",
        "      scores_df = get_scores_from_soup(maxpreps_soup, content_date)\n",
        "      return scores_df\n",
        "    else:\n",
        "      print('No Games found for {}'.format(today))\n",
        "  except TypeError:\n",
        "    print('No Games found for {}'.format(today))\n",
        "  except ValueError:\n",
        "    print('No Games found for {}'.format(today))\n",
        "\n",
        "\n",
        "def get_scores_from_maxpreps_for_range(start_date, end_date):\n",
        "  \"\"\"to get scores of games from MaxPreps in a date range.\n",
        "\n",
        "  Example:\n",
        "  start_date = date(2022, 11, 10)\n",
        "  end_date = date(2023, 2, 10)\n",
        "  scores = get_scores_from_maxpreps_for_range(start_date, end_date)\n",
        "\n",
        "  Args:\n",
        "      start_date (date): the start date.\n",
        "      end_date (date): the end date.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "  def daterange(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "  dfs = []\n",
        "  for single_date in daterange(start_date, end_date):\n",
        "      today = single_date.strftime(\"%m/%d/%Y\")\n",
        "      scores_df = get_scores_from_maxpreps_for_one_day(today)\n",
        "      if scores_df is None:\n",
        "        print('No games found on {}'.format(today))\n",
        "      else:\n",
        "        print('Found {} games for {}'.format(len(scores_df), today))\n",
        "      dfs.append(scores_df)\n",
        "\n",
        "  # see pd.concat documentation for more info\n",
        "  concat_scores_df = pd.concat(dfs)\n",
        "  concat_scores_df = concat_scores_df.drop_duplicates(keep='last')\n",
        "  return concat_scores_df\n"
      ],
      "metadata": {
        "id": "XG32BV0UzUii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Script"
      ],
      "metadata": {
        "id": "qGqG335tPH0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demo\n",
        "df = get_scores_from_maxpreps_for_one_day(\"3/8/2025\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "vVlhCgezUxXt",
        "outputId": "ae727058-6399-41ee-b010-ed225903121e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\r\n",
            "\n",
            "Found Games for 2025-03-08 00:00:00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'append'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0ff71cf9e679>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# demo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scores_from_maxpreps_for_one_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3/8/2025\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-47f212a75902>\u001b[0m in \u001b[0;36mget_scores_from_maxpreps_for_one_day\u001b[0;34m(today)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontent_date\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found Games for {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m       \u001b[0mscores_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scores_from_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxpreps_soup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mscores_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-47f212a75902>\u001b[0m in \u001b[0;36mget_scores_from_soup\u001b[0;34m(maxpreps_day_soup, this_day)\u001b[0m\n\u001b[1;32m     61\u001b[0m     m_result = {'Date':this_day, 'Home Team':home_name, 'Home Score':home_score, \n\u001b[1;32m     62\u001b[0m                 'Away Team':away_name, 'Away Score':away_score}\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mschedule_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mschedule_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all scores\n",
        "# please note game info of previous seasons/years are not accessible,\n",
        "# only current season is accessible.\n",
        "\n",
        "# load historical data\n",
        "# scores.csv was generated between 11/10/2022 and 2/1/2023\n",
        "hist_scores = pd.read_csv('/drive/My Drive/scores.csv')\n",
        "\n",
        "start_date = date(2025, 2, 1)\n",
        "end_date = date(2025, 3, 12)\n",
        "new_scores = get_scores_from_maxpreps_for_range(start_date, end_date)\n",
        "\n",
        "scores = pd.concat([hist_scores, new_scores])\n",
        "scores['Date'] = pd.to_datetime(scores['Date'])\n",
        "scores = scores.drop_duplicates(keep='last')\n",
        "scores.to_csv('/drive/My Drive/scores_2425_03122025.csv', index=False)"
      ],
      "metadata": {
        "id": "GuJkF8RrOaut",
        "outputId": "9ebd94ef-f5ef-4f8f-cc31-7ceb328f02a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/1/2025 Results\r\n",
            "\n",
            "Found Games for 2025-02-01 00:00:00\n",
            "Found 6 games for 02/01/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/02/2025\n",
            "No games found on 02/02/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/3/2025 Results\n",
            "\n",
            "Found Games for 2025-02-03 00:00:00\n",
            "score not valid, using -1 instead\n",
            "Found 11 games for 02/03/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/4/2025 Results\n",
            "\n",
            "Found Games for 2025-02-04 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 29 games for 02/04/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/5/2025 Results\n",
            "\n",
            "Found Games for 2025-02-05 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 18 games for 02/05/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/6/2025 Results\n",
            "\n",
            "Found Games for 2025-02-06 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 34 games for 02/06/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/7/2025 Results\n",
            "\n",
            "Found Games for 2025-02-07 00:00:00\n",
            "Found 17 games for 02/07/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/8/2025 Results\n",
            "\n",
            "Found Games for 2025-02-08 00:00:00\n",
            "Found 7 games for 02/08/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/09/2025\n",
            "No games found on 02/09/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/10/2025 Results\n",
            "\n",
            "Found Games for 2025-02-10 00:00:00\n",
            "Found 7 games for 02/10/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/11/2025 Results\n",
            "\n",
            "Found Games for 2025-02-11 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 39 games for 02/11/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/12/2025 Results\n",
            "\n",
            "Found Games for 2025-02-12 00:00:00\n",
            "score not valid, using -1 instead\n",
            "Found 15 games for 02/12/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/13/2025 Results\n",
            "\n",
            "Found Games for 2025-02-13 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 30 games for 02/13/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/14/2025 Results\n",
            "\n",
            "Found Games for 2025-02-14 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 16 games for 02/14/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/15/2025 Results\n",
            "\n",
            "Found Games for 2025-02-15 00:00:00\n",
            "Found 7 games for 02/15/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/16/2025\n",
            "No games found on 02/16/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/17/2025 Results\n",
            "\n",
            "Found Games for 2025-02-17 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "Found 5 games for 02/17/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/18/2025 Results\n",
            "\n",
            "Found Games for 2025-02-18 00:00:00\n",
            "Found 13 games for 02/18/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/19/2025 Results\n",
            "\n",
            "Found Games for 2025-02-19 00:00:00\n",
            "Found 8 games for 02/19/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/20/2025\n",
            "No games found on 02/20/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/21/2025\n",
            "No games found on 02/21/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/22/2025 Results\n",
            "\n",
            "Found Games for 2025-02-22 00:00:00\n",
            "Found 20 games for 02/22/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/23/2025\n",
            "No games found on 02/23/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/24/2025\n",
            "No games found on 02/24/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/25/2025 Results\n",
            "\n",
            "Found Games for 2025-02-25 00:00:00\n",
            "Found 2 games for 02/25/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/26/2025 Results\n",
            "\n",
            "Found Games for 2025-02-26 00:00:00\n",
            "Found 8 games for 02/26/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 02/27/2025\n",
            "No games found on 02/27/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/28/2025 Results\n",
            "\n",
            "Found Games for 2025-02-28 00:00:00\n",
            "Found 1 games for 02/28/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/1/2025 Results\n",
            "\n",
            "Found Games for 2025-03-01 00:00:00\n",
            "Found 4 games for 03/01/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/02/2025\n",
            "No games found on 03/02/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/03/2025\n",
            "No games found on 03/03/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/4/2025 Results\n",
            "\n",
            "Found Games for 2025-03-04 00:00:00\n",
            "Found 8 games for 03/04/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/05/2025\n",
            "No games found on 03/05/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/6/2025 Results\n",
            "\n",
            "Found Games for 2025-03-06 00:00:00\n",
            "Found 5 games for 03/06/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/07/2025\n",
            "No games found on 03/07/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "Found Games for 2025-03-08 00:00:00\n",
            "Found 2 games for 03/08/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/09/2025\n",
            "No games found on 03/09/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/10/2025\n",
            "No games found on 03/10/2025\n",
            "\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 3/8/2025 Results\n",
            "\n",
            "No Games found for 03/11/2025\n",
            "No games found on 03/11/2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all rankings\n",
        "rankings = get_rankings_from_scores(scores)\n",
        "rankings.to_csv('/drive/My Drive/rankings_2425_03122025.csv', index=False)"
      ],
      "metadata": {
        "id": "sah_im9Sr2a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "CTCxzxmrjPkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Method"
      ],
      "metadata": {
        "id": "fydMxgKcV-ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new dataset for the scores and rankings\n",
        "# one shot (not combining)\n",
        "\n",
        "# combine with historical data"
      ],
      "metadata": {
        "id": "SDDWC6P9WClY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test of Script"
      ],
      "metadata": {
        "id": "IR1OlpxXM9_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rankings_from_scores(schedule_df):\n",
        "  \"\"\"to ranking statistics of teams from the schedules and scores\n",
        "\n",
        "  Example:\n",
        "  df = get_scores_from_maxpreps_for_one_day(\"12/1/2022\")\n",
        "  print(df)\n",
        "\n",
        "  Args:\n",
        "      schedule_df (dataframe): the scores dataframe.\n",
        "\n",
        "  Returns:\n",
        "      ranking_df (dataframe): the dataframe of ranking statistics.\n",
        "\n",
        "  \"\"\"\n",
        "  teams = list(set(list(schedule_df[\"Home Team\"].unique()) +\n",
        "                   list(schedule_df[\"Away Team\"].unique())))\n",
        "\n",
        "  # initialize the ranking dataframe\n",
        "  ranking_df = pd.DataFrame({\n",
        "                    'Team': pd.Series(dtype='str'),\n",
        "                    'Total Points': pd.Series(dtype='int'),\n",
        "                    'Total Games': pd.Series(dtype='int'),\n",
        "                    'Total Wins': pd.Series(dtype='int'),\n",
        "                    'Total Losses': pd.Series(dtype='int'),\n",
        "                    'Total Ties': pd.Series(dtype='int'),\n",
        "                    'PPG': pd.Series(dtype='float'),})\n",
        "\n",
        "  for t in teams:\n",
        "    t_result = {'Team':t, 'Total Points': 0,\n",
        "                    'Total Games': 0,\n",
        "                    'Total Wins': 0,\n",
        "                    'Total Losses': 0,\n",
        "                    'Total Ties': 0,\n",
        "                    'PPG':0}\n",
        "    # ranking_df = ranking_df.append(t_result, ignore_index=True)\n",
        "    ranking_df = pd.concat([ranking_df, pd.DataFrame([t_result])], ignore_index=True)\n",
        "\n",
        "\n",
        "  # populate ranking dataframe based on schedule\n",
        "  for index,row in schedule_df.iterrows():\n",
        "    home_team = row['Home Team']\n",
        "    away_team = row['Away Team']\n",
        "    home_score = row['Home Score']\n",
        "    away_score = row['Away Score']\n",
        "\n",
        "    ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Games'] += 1\n",
        "    ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Games'] += 1\n",
        "\n",
        "    if home_score > away_score: # home win\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Wins'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Points'] += 3\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Losses'] += 1\n",
        "    elif home_score < away_score: # away win\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Wins'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Points'] += 3\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Losses'] += 1\n",
        "    elif home_score == away_score: # tie\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Ties'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Ties'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Points'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Points'] += 1\n",
        "\n",
        "  ranking_df['PPG'] = ranking_df['Total Points'] / ranking_df['Total Games']\n",
        "\n",
        "  ranking_df = ranking_df.sort_values(by=['PPG', 'Total Points'],\n",
        "                                      ascending=False)\n",
        "  ranking_df = ranking_df.drop_duplicates(keep='last')\n",
        "  return ranking_df\n"
      ],
      "metadata": {
        "id": "nksiVfx8w3O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### analyze game summary page"
      ],
      "metadata": {
        "id": "SLbKiODcAHzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_date =  date(2023, 2, 28)\n",
        "today = single_date.strftime(\"%m/%d/%Y\")\n",
        "\n",
        "# maxpreps's homepage\n",
        "maxpreps_url = 'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today)  # please change the date if needed\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "maxpreps_response = requests.get(maxpreps_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "maxpreps_soup = BeautifulSoup(maxpreps_response.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "biTur2QgM7iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find all the div (each div is a game) and print a link in each div\n",
        "for gamediv in maxpreps_soup.find_all(\"div\", {\"class\": \"contest-box-item\"}):#maxpreps_soup.findAll('a', {'class': 'c-c'}):\n",
        "    try:\n",
        "        # print(gamediv['href'])\n",
        "        # print(gamediv)\n",
        "        print(gamediv.find('a')['href'])\n",
        "    except KeyError:\n",
        "        print(\"no href\")\n",
        "        pass"
      ],
      "metadata": {
        "id": "jSV0LmfhSSF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find  details of one game using the link\n",
        "# game_detail_page = \"https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/presentation-vs-windsor.htm?c=kWgQYflpLk60D3-K60z9pA\" # simple example\n",
        "game_detail_page = \"https://www.maxpreps.com/games/2-22-2023/girls-soccer-winter-22-23/menlo-atherton-vs-mountain-view.htm?c=JPH2i5aDH0yYvdk1bipRfg\" # complete example\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "gamedetail_response = requests.get(game_detail_page, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "gamedetail_soup = BeautifulSoup(gamedetail_response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "QmTxCOCFCYp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Classes of each table:')\n",
        "# for table in gamedetail_soup.find_all('table'):\n",
        "#     print(table.get('class'))\n",
        "\n",
        "def get_text(ele):\n",
        "  return ele.text if ele is not None else None\n",
        "\n",
        "\n",
        "def find_city(team_name, summary):\n",
        "  \"\"\" find city of team from summary\n",
        "  \"\"\"\n",
        "  res = re.search(r'{} \\((.*?)\\)'.format(team_name), summary, re.IGNORECASE)\n",
        "  if res:\n",
        "      return res.group(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# need to record howm/away information in one row"
      ],
      "metadata": {
        "id": "iDTaFPw_SuoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create a dataframe from statistics page"
      ],
      "metadata": {
        "id": "ebe4CSAyDjGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find info for a game from its details url\n",
        "def extract_game_info_from_details_page(page_url):\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  page_response = requests.get(page_url,\n",
        "                               headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
        "\n",
        "  # find summary\n",
        "  game_summary = get_text(page_soup.find('p', attrs={'class' : 'contest-description'}))\n",
        "  # print(game_summary)\n",
        "\n",
        "  # find school names (names in table are not reliable)\n",
        "  school_names = [i.text for i in page_soup.find('div', attrs={'class' : 'school-names'}).find_all('a')]\n",
        "  # print(school_names)\n",
        "\n",
        "  # analyze target table\n",
        "  table = page_soup.find('div' , {\"data-l-s-c\":\"box-score\"}).find('table', class_='mx-grid boxscore d-b-s post soccer')\n",
        "  # print(table)\n",
        "\n",
        "  team_names = []\n",
        "  team_cities = []\n",
        "  first_half_scores = []\n",
        "  second_half_scores = []\n",
        "  total_scores = []\n",
        "  shootout_scores = []\n",
        "  is_winner = []\n",
        "\n",
        "  try:\n",
        "    for r in table.tbody.find_all('tr'):\n",
        "      # find team name\n",
        "      team_name = get_text(r.find('th', class_='team first'))\n",
        "      team_names.append(team_name)\n",
        "      # team_cities.append(find_city(team_name, game_summary))\n",
        "      first_half_scores.append(get_text(r.find('td', class_='firsthalf score dw')))\n",
        "      second_half_scores.append(get_text(r.find('td', class_='secondhalf score dw')))\n",
        "      total_scores.append(get_text(r.find('td', class_='score total score')))\n",
        "      shootout_scores.append(get_text(r.find('td', class_='shootout stat tiebreaker dw')))\n",
        "      is_winner.append(get_text(r.find('td', class_='winner last')))\n",
        "  except AttributeError as err:\n",
        "    print(err)\n",
        "    pass\n",
        "\n",
        "  # team_names = [j if i != j else i for i, j in zip(team_names, school_names)]\n",
        "  team_names = school_names\n",
        "  team_cities = [find_city(j, game_summary) for j in team_names]\n",
        "  return team_names, team_cities, first_half_scores, second_half_scores, total_scores, shootout_scores, is_winner, game_summary\n",
        "\n",
        "game_detail_page1 = \"https://www.maxpreps.com/games/2-28-2023/girls-soccer-winter-22-23/presentation-vs-windsor.htm?c=kWgQYflpLk60D3-K60z9pA\" # simple example\n",
        "game_detail_page2 = \"https://www.maxpreps.com/games/2-22-2023/girls-soccer-winter-22-23/menlo-atherton-vs-mountain-view.htm?c=JPH2i5aDH0yYvdk1bipRfg\" # complete example with shootout\n",
        "game_detail_page3 = \"https://www.maxpreps.com/games/3-2-2023/girls-soccer-winter-22-23/hollister-vs-stone-ridge-christian.htm?c=tv8S33dtGkSS-2ZuVO0vLg\"\n",
        "game_detail_page4 = \"https://www.maxpreps.com/games/11-29-2022/girls-soccer-winter-22-23/gateway-vs-oceana.htm?c=70Hrb_EAd0mWPDTpdhiXoQ\" # example of missing scores\n",
        "game_detail_page5 = \"https://www.maxpreps.com/games/1-6-2023/girls-soccer-winter-22-23/king-city-vs-st-francis.htm?c=ImFn1XMo2EGTXl-9PYtm0A\" # no game result is reported\n",
        "\n",
        "# print(extract_game_info_from_details_page(game_detail_page1))\n",
        "# print(extract_game_info_from_details_page(game_detail_page2))\n",
        "print(extract_game_info_from_details_page(game_detail_page3))\n",
        "print(extract_game_info_from_details_page(game_detail_page5))"
      ],
      "metadata": {
        "id": "_47PmRpnF50l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract team info from school profile page\n",
        "def extract_team_info_from_profile_page(school_profile_url):\n",
        "  \"\"\"\n",
        "  return school name, address, mascot, color, school type, athletic director, phone\n",
        "  \"\"\"\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  page_response = requests.get(school_profile_url,\n",
        "                               headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
        "\n",
        "  school_name = page_soup.find(\"h1\").string\n",
        "\n",
        "  dl_data = page_soup.find_all(\"dd\")\n",
        "  info_list = [dl.text for dl in dl_data]\n",
        "\n",
        "  return tuple([school_name] + info_list)\n",
        "team_profile_page1 = \"https://www.maxpreps.com/ca/mountain-view/mountain-view-spartans\"\n",
        "\n",
        "print(extract_team_info_from_profile_page(team_profile_page1))\n",
        "\n"
      ],
      "metadata": {
        "id": "LiFdPCtwt_iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find team profile page url from game page url\n",
        "def find_team_profile_pages(game_page_url):\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  page_response = requests.get(game_page_url,\n",
        "                               headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
        "\n",
        "  page_urls = []\n",
        "  for sdiv in page_soup.find_all(\"div\", {\"class\": \"school-names\"}):\n",
        "    for l in sdiv.find_all('a'):\n",
        "      page_urls.append(\"https://www.maxpreps.com\"+l['href'])\n",
        "  return page_urls\n",
        "\n",
        "game_detail_page5 = \"https://www.maxpreps.com/games/1-6-2023/girls-soccer-winter-22-23/king-city-vs-st-francis.htm?c=ImFn1XMo2EGTXl-9PYtm0A\" # no game result is reported\n",
        "print(find_team_profile_pages(game_detail_page5))"
      ],
      "metadata": {
        "id": "fFZz0IqC4mNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# create dataframe of teams\n",
        "\n",
        "teams_df = pd.DataFrame({'School Name': pd.Series(dtype='str'),\n",
        "                         'School Alias': pd.Series(dtype='str'),\n",
        "                        'School Address': pd.Series(dtype='str'),\n",
        "                        'Mascot': pd.Series(dtype='int'),\n",
        "                        'School Link': pd.Series(dtype='str'),\n",
        "                        'Team Link': pd.Series(dtype='str')})\n",
        "\n",
        "# load schedule df to\n",
        "# step 1: find team link from each game details page\n",
        "# step 2: add a record of team info\n",
        "# step 3: dedupe\n",
        "# note: moving forward we don't need to parse school info from game details page\n",
        "\n",
        "hist_scores_df = pd.read_csv('/drive/My Drive/scores_2223_03182023.csv')\n",
        "for index, row in tqdm(hist_scores_df.iterrows(), total=hist_scores_df.shape[0]):\n",
        "    game_url = row['Web Link']\n",
        "    team_profile_urls = find_team_profile_pages(game_url)\n",
        "    for u in team_profile_urls:\n",
        "        school_profile_url = u.removesuffix(\"soccer/girls/winter/schedule/\")\n",
        "        info_list = extract_team_info_from_profile_page(school_profile_url)\n",
        "        try:\n",
        "          # pd.concat([new_row,df.loc[:]]).reset_index(drop=True)\n",
        "          m_result = pd.DataFrame({'School Name':info_list[0],\n",
        "                      'School Alias':\"\",\n",
        "                      'School Address':info_list[1],\n",
        "                      'Mascot':info_list[2],\n",
        "                      'School Link':school_profile_url,\n",
        "                      'Team Link':u }, index=[0])\n",
        "          teams_df = pd.concat([m_result, teams_df.loc[:]]).reset_index(drop=True)\n",
        "          # teams_df = teams_df.append(m_result, ignore_index=True)\n",
        "        except IndexError as err:\n",
        "          print(err)\n",
        "          print(school_profile_url)\n",
        "          print(u)\n",
        "\n",
        "teams_df = teams_df.drop_duplicates(keep='last')\n",
        "# teams_df.to_csv('/drive/My Drive/teams_2223_03182023.csv', index=False)\n",
        "print(teams_df)\n"
      ],
      "metadata": {
        "id": "drhgrzNP0aFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dateframe of game information\n",
        "def create_game_info_dataframe_from_stats_page(page_url, today):\n",
        "  \"\"\" create game info dataframe from a stats page\n",
        "\n",
        "  today: Date object\n",
        "\n",
        "  note: details page has no date\n",
        "  return dataframe\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  page_response = requests.get(page_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
        "\n",
        "  # verify the date\n",
        "  title_date = datetime.strptime(page_soup.title.text.split('|')[1].strip().split()[0], '%m/%d/%Y').date()\n",
        "  # print(page_soup.title.text.split('|')[1].strip().split()[0])\n",
        "  # print(title_date)\n",
        "  # print(today)\n",
        "\n",
        "  if title_date == today:\n",
        "      print('Found Games for {}'.format(title_date))\n",
        "      schedule_df = pd.DataFrame({'Date': pd.Series(dtype='datetime64[ns]'),\n",
        "                                'Home Team': pd.Series(dtype='str'),\n",
        "                                'Home City': pd.Series(dtype='str'),\n",
        "                                'Home Score': pd.Series(dtype='int'),\n",
        "                                'Away Team': pd.Series(dtype='str'),\n",
        "                                'Away City': pd.Series(dtype='str'),\n",
        "                                'Away Score': pd.Series(dtype='int'),\n",
        "                                'Game Summary': pd.Series(dtype='str'),\n",
        "                                'Web Link': pd.Series(dtype='str')})\n",
        "      # find all the div (each div is a game) and print a link in each div\n",
        "      for gamediv in page_soup.find_all(\"div\", {\"class\": \"contest-box-item\"}):#maxpreps_soup.findAll('a', {'class': 'c-c'}):\n",
        "          try:\n",
        "              game_detail_url = gamediv.find('a')['href']\n",
        "              print(game_detail_url)\n",
        "              team_names, team_cities, first_half_scores, second_half_scores, total_scores, shootout_scores, is_winner, game_summary = extract_game_info_from_details_page(game_detail_url)\n",
        "              if len(total_scores)==2:\n",
        "                  if shootout_scores[0] == None or shootout_scores[1]==None:\n",
        "                    m_result = {'Date':today,\n",
        "                                'Home Team':team_names[1],\n",
        "                                'Home City':team_cities[1],\n",
        "                                'Home Score':total_scores[1],\n",
        "                                'Away Team':team_names[0],\n",
        "                                'Away City':team_cities[0],\n",
        "                                'Away Score':total_scores[0],\n",
        "                                'Game Summary': game_summary,\n",
        "                                'Web Link': game_detail_url}\n",
        "                  else:\n",
        "                    m_result = {'Date':today,\n",
        "                                'Home Team':team_names[1],\n",
        "                                'Home City':team_cities[1],\n",
        "                                'Home Score':shootout_scores[1],\n",
        "                                'Away Team':team_names[0],\n",
        "                                'Away City':team_cities[0],\n",
        "                                'Away Score':shootout_scores[0],\n",
        "                                'Game Summary': game_summary,\n",
        "                                'Web Link': game_detail_url}\n",
        "                  # schedule_df = schedule_df.append(m_result, ignore_index=True)\n",
        "                  schedule_df = pd.concat([schedule_df, pd.DataFrame([m_result])], ignore_index=True)\n",
        "          except (KeyError, TypeError) as err:\n",
        "              print(err)\n",
        "              pass\n",
        "\n",
        "      return schedule_df\n",
        "  else:\n",
        "      print('No Games for {}'.format(today))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BD8cT1NnDv-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = date(2022, 11, 29)\n",
        "maxpreps_url = 'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today.strftime(\"%m/%d/%Y\"))\n",
        "print(maxpreps_url)\n",
        "\n",
        "\n",
        "print(create_game_info_dataframe_from_stats_page(maxpreps_url, today))"
      ],
      "metadata": {
        "id": "cjE07j2bYLbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reprocess all season data\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "start_date = date(2022, 11, 1)\n",
        "end_date = date(2023, 3, 18)\n",
        "\n",
        "def daterange(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "dfs = []\n",
        "for today in tqdm(daterange(start_date, end_date)):\n",
        "    # print('https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today.strftime(\"%m/%d/%Y\")) )\n",
        "    scores_df = create_game_info_dataframe_from_stats_page(\n",
        "        'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today.strftime(\"%m/%d/%Y\")) ,\n",
        "        today)\n",
        "    if scores_df is not None:\n",
        "      print('Found {} games for {}'.format(len(scores_df), today))\n",
        "    dfs.append(scores_df)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "if len(dfs)>0:\n",
        "  scores_df = pd.concat(dfs)\n",
        "  scores_df = scores_df.drop_duplicates(keep='last')\n",
        "  print(scores_df)\n",
        "\n",
        "\n",
        "# scores['Date'] = pd.to_datetime(scores['Date'])\n",
        "# scores = scores.drop_duplicates(keep='last')\n",
        "scores_df.to_csv('/drive/My Drive/scores_2223_03182023.csv', index=False)"
      ],
      "metadata": {
        "id": "9GZm39OsYVtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all rankings\n",
        "rankings = get_rankings_from_scores(scores_df)\n",
        "rankings.to_csv('/drive/My Drive/rankings_2223_03182023.csv', index=False)"
      ],
      "metadata": {
        "id": "h_cUwpCNjVvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install maxpreps_scraper"
      ],
      "metadata": {
        "id": "PobVp15l9EVJ",
        "outputId": "231d25ec-e866-4831-9569-54899cbb2379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting maxpreps_scraper\n",
            "  Downloading maxpreps_scraper-0.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from maxpreps_scraper) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from maxpreps_scraper) (4.13.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from maxpreps_scraper) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from maxpreps_scraper) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from maxpreps_scraper) (5.3.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from maxpreps_scraper) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->maxpreps_scraper) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->maxpreps_scraper) (4.13.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->maxpreps_scraper) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->maxpreps_scraper) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->maxpreps_scraper) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->maxpreps_scraper) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->maxpreps_scraper) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->maxpreps_scraper) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->maxpreps_scraper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->maxpreps_scraper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->maxpreps_scraper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->maxpreps_scraper) (2025.1.31)\n",
            "Downloading maxpreps_scraper-0.1.2-py3-none-any.whl (7.1 kB)\n",
            "Installing collected packages: maxpreps_scraper\n",
            "Successfully installed maxpreps_scraper-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrape Data"
      ],
      "metadata": {
        "id": "cIKe5hwrTb-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from maxpreps_scraper import MaxPrepsScraper\n",
        "scraper = MaxPrepsScraperV1()\n",
        "\n",
        "state = 'tx'\n",
        "sport = 'soccer'\n",
        "year = '21-22'\n",
        "# Get Team Rankings\n",
        "# rankings_df = scraper.get_rankings(state = 'de', sport = 'football', year = '23-24')\n",
        "\n",
        "# Get Contest Data\n",
        "contests_df = scraper.get_contests(state=state, sport=sport, year=year, boys=False)\n",
        "\n",
        "#output datframes\n",
        "# rankings_df.head(10)\n",
        "contests_df.head(10)\n",
        "contests_df.to_csv(f'/drive/My Drive/games_{state}_{sport}_{year}_girls.csv', index=False)"
      ],
      "metadata": {
        "id": "rqbQC1W_8_Vo",
        "outputId": "b3471224-7d24-4623-cce1-f22bb0c0dcfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  11%|█▏        | 80/709 [00:09<00:55, 11.43 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/san-antonio/madison-mavericks/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/temple/lake-belton-broncos/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScraping Schools for  tx:  12%|█▏        | 83/709 [00:09<00:45, 13.73 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/mesquite/horn-jaguars/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScraping Schools for  tx:  12%|█▏        | 85/709 [00:10<01:11,  8.72 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/el-paso/franklin-cougars/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/melissa/melissa-cardinals/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/spring/grand-oaks-grizzlies/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  14%|█▎        | 96/709 [00:10<00:55, 11.11 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/austin/austin-maroons/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  14%|█▍        | 102/709 [00:11<00:41, 14.61 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/arlington/martin-warriors/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/dallas/wilson-wildcats/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  15%|█▌        | 107/709 [00:11<00:38, 15.45 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/richmond/foster-falcons/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/hurst/bell-blue-raiders/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/austin/anderson-trojans/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  16%|█▌        | 115/709 [00:12<00:52, 11.24 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/frisco/lebanon-trail-trail-blazers/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/buda/johnson-jaguars/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/mcallen/mcallen-bulldogs/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  18%|█▊        | 125/709 [00:13<00:45, 12.88 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/new-braunfels/new-braunfels-unicorns/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/austin/mcneil-mavericks/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/harlingen/harlingen-cardinals/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/corinth/lake-dallas-falcons/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  18%|█▊        | 131/709 [00:13<00:37, 15.54 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/wichita-falls/wichita-falls-coyotes/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScraping Schools for  tx:  19%|█▉        | 133/709 [00:13<00:41, 13.74 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/stephenville/stephenville-yellow-jackets-honeybees/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/bay-city/bay-city-blackcats/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  19%|█▉        | 138/709 [00:14<00:38, 14.73 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/kingwood/kingwood-park-panthers/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/plano/john-paul-ii-cardinals/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScraping Schools for  tx:  20%|█▉        | 141/709 [00:14<00:34, 16.57 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/tomball/tomball-cougars/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  20%|██        | 145/709 [00:14<00:41, 13.67 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/san-antonio/san-antonio-christian-lions/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/fulshear/jordan-warriors/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  21%|██        | 150/709 [00:15<00:50, 11.11 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/edinburg/vela-sabercats/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/corpus-christi/calallen-wildcats/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/pflugerville/weiss-wolves/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  22%|██▏       | 154/709 [00:15<00:47, 11.81 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/houston/klein-cain-hurricanes/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/kingwood/kingwood-mustangs/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  23%|██▎       | 162/709 [00:16<00:45, 11.95 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/jacksonville/jacksonville-fightin-indians/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  23%|██▎       | 166/709 [00:16<01:04,  8.38 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/spring/klein-collins-tigers/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/longview/pine-tree-pirates/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  25%|██▌       | 178/709 [00:17<00:48, 10.86 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/the-woodlands/college-park-cavaliers/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  27%|██▋       | 191/709 [00:19<00:49, 10.38 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/paris/paris-wildcats/soccer/girls/winter/21-22/schedule/ (status code: 500)\n",
            "Failed to fetch /tx/montgomery/montgomery-bears/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScraping Schools for  tx:  27%|██▋       | 194/709 [00:19<00:55,  9.31 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/brownsville/porter-cowboys/soccer/girls/winter/21-22/schedule/ (status code: 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  31%|███       | 219/709 [00:25<02:53,  2.82 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/bellaire/bellaire-cardinals/soccer/girls/winter/21-22/schedule/ (status code: 504)\n",
            "Failed to fetch /tx/brownsville/hanna-golden-eagles/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  31%|███▏      | 223/709 [00:25<01:26,  5.64 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/palestine/palestine-wildcats/soccer/girls/winter/21-22/schedule/ (status code: 504)\n",
            "Failed to fetch /tx/port-neches/port-neches-groves-indians/soccer/girls/winter/21-22/schedule/ (status code: 504)\n",
            "Failed to fetch /tx/san-antonio/antonian-prep-apaches/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScraping Schools for  tx:  32%|███▏      | 225/709 [00:25<01:25,  5.67 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/fort-worth/paschal-panthers/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  33%|███▎      | 232/709 [00:26<01:01,  7.76 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/el-paso/jefferson-silver-foxes/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  34%|███▎      | 239/709 [00:27<00:40, 11.63 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/deer-park/deer-park-deer/soccer/girls/winter/21-22/schedule/ (status code: 504)\n",
            "Failed to fetch /tx/el-paso/bel-air-highlanders/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  36%|███▋      | 258/709 [00:30<00:58,  7.77 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/copperas-cove/copperas-cove-bulldawgs/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  37%|███▋      | 262/709 [00:31<01:35,  4.66 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/san-elizario/san-elizario-eagles/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  39%|███▉      | 276/709 [00:32<00:36, 12.00 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/plano/plano-east-panthers/soccer/girls/winter/21-22/schedule/ (status code: 504)\n",
            "Failed to fetch /tx/forney/north-forney-falcons/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx:  41%|████      | 288/709 [00:33<00:41, 10.27 schools/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch /tx/houston/langham-creek-lobos/soccer/girls/winter/21-22/schedule/ (status code: 504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping Schools for  tx: 100%|██████████| 709/709 [01:20<00:00,  8.81 schools/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data collected before cleaning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(contests_df.columns)"
      ],
      "metadata": {
        "id": "5sDHCt__FP-o",
        "outputId": "026358e9-b370-4288-94f3-00a1c2376115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Team 1', 'Team 2', 'Team 1 Score', 'Team 2 Score', 'Outcome',\n",
            "       'Forfeit', 'Venue', 'Game Type', 'Team 1 Address', 'Team 1 City',\n",
            "       'Team 1 State', 'Team 1 Zipcode', 'Team 1 URL', 'Team 2 URL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show maxpreps-scraper"
      ],
      "metadata": {
        "id": "7NgsMts8F3eS",
        "outputId": "4041a9c1-3c8b-4caa-b12c-26ffd987dfca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: maxpreps-scraper\n",
            "Version: 0.1.2\n",
            "Summary: A Python scraper for MaxPreps high school sports data\n",
            "Home-page: https://github.com/raghavdhir03/maxpreps_scraper\n",
            "Author: Raghav Dhir\n",
            "Author-email: dhir.raghav@gmail.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: beautifulsoup4, html5lib, lxml, pandas, requests, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Function"
      ],
      "metadata": {
        "id": "11SoAtcUTK5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import concurrent.futures\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import re\n",
        "\n",
        "class MaxPrepsScraperV1():\n",
        "\n",
        "    BASE_URL = 'https://www.maxpreps.com'\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize scraper settings (headers, session, etc.).\"\"\"\n",
        "        self.session = requests.Session()\n",
        "\n",
        "    def get_rankings(self, state: str, sport: str, year: str, boys=True):\n",
        "        \"\"\"\n",
        "        Get rankings for a given sport, state, and year.\n",
        "        Returns a Pandas DataFrame with:\n",
        "        - School Name\n",
        "        - State Rank\n",
        "        - Strength of Schedule (SOS)\n",
        "        - Team Rating\n",
        "        - Team URL\n",
        "        \"\"\"\n",
        "\n",
        "        if sport not in ['basketball', 'football', 'baseball', 'soccer', 'volleyball', 'lacrosse', 'softball']:\n",
        "            raise ValueError(f\"Sport '{sport}' is not supported. Please choose from: basketball, football, baseball, soccer, volleyball, lacrosse, softball\")\n",
        "\n",
        "        if (boys == False and sport in ['football', 'baseball']) or (boys and sport in ['softball', 'volleyball']):\n",
        "            raise ValueError(f\"{'boys' if boys else 'girls'} {sport} is not supported\")\n",
        "\n",
        "        if sport == 'soccer' and state not in ['tx', 'la', 'ms', 'hi', 'ca', 'fl', 'az']:\n",
        "            raise ValueError(f\"Soccer is not supported in {state}\")\n",
        "\n",
        "        state_url = f\"{self.BASE_URL}/{state}/{sport}/{'' if (boys or sport in ['softball', 'volleyball']) else 'girls/'}{'winter/' if sport == 'soccer' else ''}{year}/rankings\"\n",
        "\n",
        "        page = 1\n",
        "        full_df = pd.DataFrame()\n",
        "\n",
        "        while True:\n",
        "            page_url = f'{state_url}/{page}/'\n",
        "\n",
        "            response = requests.get(page_url)\n",
        "\n",
        "            # Stop if the page does not exist\n",
        "            if response.status_code != 200:\n",
        "                break\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # You can add extra checks here to stop if there's no data\n",
        "            table = soup.find('table')\n",
        "            if not table:\n",
        "                break\n",
        "\n",
        "            # Process your table here\n",
        "            df = self._scrape_table(soup)\n",
        "\n",
        "            full_df = pd.concat([full_df, df]).reset_index(drop=True)\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        full_df['Team'] = full_df['Team'].str.replace(r'^([A-Z])\\1', r'\\1', regex=True) #take care of schools with no mascot. Turns AAustin into Austin\n",
        "\n",
        "        return full_df\n",
        "\n",
        "    #sports that this function suppoprts: basketball, football, baseball, soccer, volleyball, lacrosse, softball,\n",
        "    def get_contests(self, state: str, sport: str, year: str, boys: bool = True, cities=None):\n",
        "\n",
        "        if sport not in ['basketball', 'football', 'baseball', 'soccer', 'volleyball', 'lacrosse', 'softball']:\n",
        "            raise ValueError(f\"Sport '{sport}' is not supported. Please choose from: basketball, football, baseball, soccer, volleyball, lacrosse, softball\")\n",
        "\n",
        "        if (boys == False and sport in ['football', 'baseball']) or (boys and sport in ['softball', 'volleyball']):\n",
        "            raise ValueError(f\"{'boys' if boys else 'girls'} {sport} is not supported\")\n",
        "\n",
        "        if sport == 'soccer' and state not in ['tx', 'la', 'ms', 'hi', 'ca', 'fl', 'az']:\n",
        "            raise ValueError(f\"Soccer is not supported in {state}\")\n",
        "\n",
        "\n",
        "        state_url = f\"{self.BASE_URL}/{state}/{sport}/{'' if (boys or sport in ['softball', 'volleyball']) else 'girls/'}{'winter/' if sport == 'soccer' else ''}{year}/rankings\"\n",
        "        page = 1\n",
        "        school_list = []\n",
        "\n",
        "        # Step 1: Collect all school links\n",
        "        while True:\n",
        "            page_url = f'{state_url}/{page}/'\n",
        "            # print(page_url)\n",
        "            response = requests.get(page_url)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                break\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            page_list = self._get_school_list(soup, cities)\n",
        "            # print(page_list)\n",
        "            school_list += page_list\n",
        "            # print(len(school_list))\n",
        "            page += 1\n",
        "\n",
        "        if year == '24-25':\n",
        "            school_list = [(name, url+f\"/{year}/schedule\") for name, url in school_list]\n",
        "\n",
        "        # print(school_list)\n",
        "\n",
        "        # Step 2: Thread-safe scrape function that still uses self._scrape_table()\n",
        "        def _fetch_and_scrape(school, url, base_url='https://www.maxpreps.com'):\n",
        "            try:\n",
        "                response = requests.get(base_url + url, timeout=10)\n",
        "                if response.status_code == 200:\n",
        "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                    table = self._scrape_table(soup)\n",
        "                    table['Team 2 URL'] = self._extract_opponent_urls(soup)\n",
        "                    location_info = self._extract_location_info(soup)\n",
        "                    table['Team 1'] = school\n",
        "                    table['Team 1 Address'] = location_info['address']\n",
        "                    table['Team 1 City'] = location_info['city']\n",
        "                    table['Team 1 State'] = location_info['state']\n",
        "                    table['Team 1 Zipcode'] = location_info['zipcode']\n",
        "                    table['Team 1 URL'] = url\n",
        "                    return table\n",
        "                else:\n",
        "                    print(f\"Failed to fetch {url} (status code: {response.status_code})\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping {school} at {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Step 3: Run threads\n",
        "\n",
        "        full_df = pd.DataFrame()\n",
        "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "            futures = [executor.submit(_fetch_and_scrape, school, url) for school, url in school_list]\n",
        "\n",
        "            with tqdm(total=len(futures), desc=f\"Scraping Schools for {', '.join(city for city in cities) if cities else ''} {state}\", unit=\" schools\") as pbar:\n",
        "                for future in as_completed(futures):\n",
        "                    result_df = future.result()\n",
        "                    if result_df is not None and not result_df.empty:\n",
        "                        full_df = pd.concat([full_df, result_df], ignore_index=True)\n",
        "                    pbar.update(1)\n",
        "\n",
        "        print(\"data collected before cleaning\")\n",
        "        full_df = self._clean_contest_data(full_df)\n",
        "\n",
        "        return full_df\n",
        "\n",
        "\n",
        "    def _scrape_table(self, soup):\n",
        "        table = soup.find('table')\n",
        "        html = str(table)\n",
        "        df = pd.read_html(StringIO(html))[0]\n",
        "        return df\n",
        "\n",
        "    def _get_school_list(self, soup, cities=None, base_url='https://www.maxpreps.com'):\n",
        "        \"\"\"\n",
        "        Extracts school names and links to schedule pages based on new MaxPreps HTML structure.\n",
        "        \"\"\"\n",
        "        school_data = []\n",
        "\n",
        "        for td in soup.find_all('td'):\n",
        "            a_tag = td.find('a', href=True)\n",
        "            # print(a_tag)\n",
        "            if a_tag and 'soccer' in a_tag['href']:\n",
        "                href = a_tag['href']\n",
        "\n",
        "                # Check if cities is None (no filter), or if any city is in the href\n",
        "                if cities is None or any(city.lower().replace(\" \", \"-\") == href.lower().split('/')[2] for city in cities):\n",
        "                    name = a_tag.get_text(strip=True)\n",
        "                    link = href\n",
        "                    school_data.append((name, link))\n",
        "\n",
        "\n",
        "        return school_data\n",
        "\n",
        "    def _extract_location_info(self, soup):\n",
        "\n",
        "        address_element = soup.select_one('address')\n",
        "        if not address_element:\n",
        "            return {\n",
        "                \"address\": None,\n",
        "                \"city\": None,\n",
        "                \"state\": None,\n",
        "                \"zipcode\": None\n",
        "            }\n",
        "\n",
        "        # Get city/state/zip from <span>\n",
        "        city_state_span = address_element.find('span')\n",
        "        if city_state_span:\n",
        "            city_state_text = city_state_span.get_text(strip=True)\n",
        "            city_state_span.decompose()  # Remove span from the address block\n",
        "        else:\n",
        "            city_state_text = \"\"\n",
        "\n",
        "        # Now get street address (without the span)\n",
        "        street_address = address_element.get_text(strip=True)\n",
        "\n",
        "        # Parse city, state, and zip using regex\n",
        "        city, state, zipcode = None, None, None\n",
        "        match = re.match(r'^(.*?),\\s*([A-Z]{2})\\s*(\\d{5})(?:-\\d{4})?$', city_state_text)\n",
        "        if match:\n",
        "            city, state, zipcode = match.groups()\n",
        "\n",
        "        return {\n",
        "            \"address\": street_address or None,\n",
        "            \"city\": city,\n",
        "            \"state\": state,\n",
        "            \"zipcode\": zipcode\n",
        "        }\n",
        "\n",
        "    def _extract_opponent_urls(self, soup): #Extracts a list of opponent URLs (or None) from the 'Opponent' column in the schedule table.\n",
        "\n",
        "        opponent_urls = []\n",
        "\n",
        "        # Find the schedule table\n",
        "        table = soup.find('table')\n",
        "        if not table:\n",
        "            return []\n",
        "        # print(table)\n",
        "\n",
        "        # Step 1: Get header row and find the column index for 'Opponent'\n",
        "        header_row = table.find('tr')\n",
        "        headers = [th.get_text(strip=True).lower() for th in header_row.find_all('th')]\n",
        "\n",
        "        try:\n",
        "            opponent_idx = headers.index('opponent')\n",
        "        except ValueError:\n",
        "            return []\n",
        "\n",
        "        # Step 2: Go through all remaining rows and get href from the opponent column\n",
        "        for row in table.find_all('tr')[1:]:  # skip header row\n",
        "            cells = row.find_all('td')\n",
        "            if len(cells) > opponent_idx:\n",
        "                opponent_cell = cells[opponent_idx]\n",
        "                a_tag = opponent_cell.find('a', href=True)\n",
        "\n",
        "                if a_tag and a_tag['href'].endswith('/schedule/'):\n",
        "                    opponent_urls.append(a_tag['href'])\n",
        "                else:\n",
        "                    opponent_urls.append(None)\n",
        "\n",
        "        return opponent_urls\n",
        "\n",
        "    def _clean_contest_data(self, df):\n",
        "        # --- 1. Clean 'Opponent' column ---\n",
        "        opponent_pattern = r'(?P<VenueRaw>vs\\.?|@)?\\s*(?P<Team2>.+?)(?P<Star>\\*{0,3})$'\n",
        "\n",
        "        opponent_info = df['Opponent'].str.extract(opponent_pattern)\n",
        "\n",
        "        # Venue\n",
        "        opponent_info['Venue'] = opponent_info['VenueRaw'].map({\n",
        "            'vs': 'Home',\n",
        "            'vs.': 'Home',\n",
        "            '@': 'Away'\n",
        "        }).fillna('Neutral')\n",
        "\n",
        "        # Game Type\n",
        "        opponent_info['Game Type'] = opponent_info['Star'].map({\n",
        "            '': 'Regular Season',\n",
        "            '*': 'District',\n",
        "            '**': 'Playoff',\n",
        "            '***': 'Tournament'\n",
        "        }).fillna('Regular Season')\n",
        "\n",
        "        df['Team 2'] = opponent_info['Team2'].str.strip()\n",
        "        df['Venue'] = opponent_info['Venue']\n",
        "        df['Game Type'] = opponent_info['Game Type']\n",
        "\n",
        "        # --- 2. Clean 'Result' column ---\n",
        "        result_pattern = r'(?P<Outcome>[WL])(?: (?P<Team1_Score>\\d+)-(?P<Team2_Score>\\d+)|\\((?P<Forfeit>FF)\\))'\n",
        "\n",
        "        result_info = df['Result'].str.extract(result_pattern)\n",
        "\n",
        "        df['Outcome'] = result_info['Outcome']\n",
        "        df['Team 1 Score'] = pd.to_numeric(result_info['Team1_Score'], errors='coerce')\n",
        "        df['Team 2 Score'] = pd.to_numeric(result_info['Team2_Score'], errors='coerce')\n",
        "        df['Forfeit'] = result_info['Forfeit'].notna()\n",
        "\n",
        "        cols_to_drop = ['Opponent', 'Result', 'Game Info', 'Match Info']\n",
        "        df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
        "\n",
        "        df.loc[df['Outcome'] == 'L', ['Team 1 Score', 'Team 2 Score']] = df.loc[df['Outcome'] == 'L', ['Team 2 Score', 'Team 1 Score']].values # Swap scores if team 1 lost\n",
        "\n",
        "        df['Team 1'] = df['Team 1'].str.replace(r'(^[A-Z])\\1', '', regex=True) #take care of schools with no mascot. Turns AAustin into Austin\n",
        "\n",
        "        # Reorder columns\n",
        "        new_order = ['Date', 'Team 1', 'Team 2', 'Team 1 Score', 'Team 2 Score', 'Outcome', 'Forfeit', 'Venue', 'Game Type', 'Team 1 Address', 'Team 1 City', 'Team 1 State', 'Team 1 Zipcode', 'Team 1 URL', 'Team 2 URL']\n",
        "        df = df[new_order]\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "soPA_n1fGdVG"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}