{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7uIItDr+zccMftkr5LtYI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhenyisx/scoutoid/blob/main/scraper2db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To scrape website and populate to database (csv file) on Google Drive. The files can then be uploaded to Goolge Storage for clients (i.e., stremlit) to consume."
      ],
      "metadata": {
        "id": "Z46myB-0fZNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Function Definitions"
      ],
      "metadata": {
        "id": "Mh_peAjDPRXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "from google.colab import  drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "_dEawkCOfhSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9329e73d-b4d0-4bd3-aec5-b16e5caa5779"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores_from_soup(maxpreps_day_soup, this_day):\n",
        "  \"\"\"to get scores of games in one day.\n",
        "\n",
        "  Args:\n",
        "      maxpreps_day_soup (soup): a soup parsed from MaxPreps HTML by BS.\n",
        "      this_day (str): the date.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # create dateframe of game schedules and scores\n",
        "  schedule_df = pd.DataFrame({'Date': pd.Series(dtype='datetime64[ns]'),\n",
        "                    'Home Team': pd.Series(dtype='str'),\n",
        "                    'Home Score': pd.Series(dtype='int'),\n",
        "                    'Away Team': pd.Series(dtype='str'),\n",
        "                    'Away Score': pd.Series(dtype='int')})\n",
        "\n",
        "  # populate the datafrme by analyzing the soup (MaxPreps specific)\n",
        "  # to use ChromeDev Tool to get the following rules of find \n",
        "  matches = maxpreps_day_soup.find('div', {'class': 'contests'})\n",
        "\n",
        "  for m in matches.find_all('ul', {'class': 'teams'}):\n",
        "    raw_record = m.find_all(\"li\")\n",
        "\n",
        "    # home score\n",
        "    try:\n",
        "      home_score = int(raw_record[0].find('div', {'class': 'score'}).text.strip())\n",
        "    except ValueError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        home_score = -1\n",
        "    except AttributeError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        home_score = -1\n",
        "    # print(home_score)\n",
        "\n",
        "    # home name\n",
        "    home_name = raw_record[0].find('div', {'class': 'name'}).text.strip()\n",
        "    # print(home_name)\n",
        "\n",
        "    # away score\n",
        "    try:\n",
        "      away_score = int(raw_record[1].find('div', {'class': 'score'}).text.strip())\n",
        "    except ValueError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        away_score = -1\n",
        "    except AttributeError:\n",
        "        # Handle the exception\n",
        "        print('score not valid, using -1 instead')\n",
        "        away_score = -1\n",
        "    # print(away_score)\n",
        "\n",
        "    # away name\n",
        "    away_name = raw_record[1].find('div', {'class': 'name'}).text.strip()\n",
        "    # print(away_name)\n",
        "\n",
        "    m_result = {'Date':this_day, 'Home Team':home_name, 'Home Score':home_score, \n",
        "                'Away Team':away_name, 'Away Score':away_score}\n",
        "    schedule_df = schedule_df.append(m_result, ignore_index=True)\n",
        "\n",
        "  schedule_df = schedule_df.drop_duplicates(keep='last')\n",
        "\n",
        "  return schedule_df\n",
        "  \n",
        "\n",
        "def get_scores_from_maxpreps_for_one_day(today):\n",
        "  \"\"\"to get scores of games from MaxPreps in one day.\n",
        "\n",
        "  Example:\n",
        "  df = get_scores_from_maxpreps_for_one_day(\"12/1/2022\")\n",
        "  print(df)\n",
        "\n",
        "  Args:\n",
        "      this_day (str): the date str in '%m/%d/%Y' format.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "  # maxpreps's homepage\n",
        "  maxpreps_url = 'https://www.maxpreps.com/ca/central-coast-section/soccer/girls/scores/?date={}'.format(today)  # please change the date if needed\n",
        "\n",
        "  # Use requests to retrieve data from a given URL\n",
        "  maxpreps_response = requests.get(maxpreps_url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
        "\n",
        "  # Parse the whole HTML page using BeautifulSoup\n",
        "  maxpreps_soup = BeautifulSoup(maxpreps_response.text, 'html.parser')\n",
        "\n",
        "  # Title of the parsed page\n",
        "  print(maxpreps_soup.title.text)\n",
        "\n",
        "  # check if the dates match\n",
        "  try:\n",
        "    content_date = datetime.strptime(maxpreps_soup.title.text.split('|')[1].strip().split()[0], '%m/%d/%Y')\n",
        "    # another way to find the content current date\n",
        "    # content = maxpreps_soup.find('div', {'class': 'calendar'}).find('ol', {'class': 'week'}).find('a', {'class': 'btn btn-default active'})\n",
        "    # content_date = datetime.strptime(content.text, '%m/%d/%Y'))\n",
        "    if content_date == datetime.strptime(today, '%m/%d/%Y'):\n",
        "      print('Found Games for {}'.format(content_date))\n",
        "      scores_df = get_scores_from_soup(maxpreps_soup, content_date)\n",
        "      return scores_df\n",
        "    else:\n",
        "      print('No Games found for {}'.format(today))\n",
        "  except TypeError:\n",
        "    print('No Games found for {}'.format(today))\n",
        "  except ValueError:\n",
        "    print('No Games found for {}'.format(today))\n",
        "\n",
        "\n",
        "def get_scores_from_maxpreps_for_range(start_date, end_date):\n",
        "  \"\"\"to get scores of games from MaxPreps in a date range.\n",
        "\n",
        "  Example:\n",
        "  start_date = date(2022, 11, 10)\n",
        "  end_date = date(2023, 2, 10)\n",
        "  scores = get_scores_from_maxpreps_for_range(start_date, end_date)\n",
        "\n",
        "  Args:\n",
        "      start_date (date): the start date.\n",
        "      end_date (date): the end date.\n",
        "\n",
        "  Returns:\n",
        "      schedulf_df (dataframe): the dataframe of all game results.\n",
        "\n",
        "  \"\"\"\n",
        "  def daterange(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "  dfs = []\n",
        "  for single_date in daterange(start_date, end_date):\n",
        "      today = single_date.strftime(\"%m/%d/%Y\")\n",
        "      scores_df = get_scores_from_maxpreps_for_one_day(today)\n",
        "      if scores_df is None:\n",
        "        print('No games found on {}'.format(today))\n",
        "      else:\n",
        "        print('Found {} games for {}'.format(len(scores_df), today))\n",
        "      dfs.append(scores_df)\n",
        "\n",
        "  # see pd.concat documentation for more info\n",
        "  concat_scores_df = pd.concat(dfs)\n",
        "  concat_scores_df = concat_scores_df.drop_duplicates(keep='last')\n",
        "  return concat_scores_df\n"
      ],
      "metadata": {
        "id": "XG32BV0UzUii"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rankings_from_scores(schedule_df):\n",
        "  \"\"\"to ranking statistics of teams from the schedules and scores\n",
        "\n",
        "  Example:\n",
        "  df = get_scores_from_maxpreps_for_one_day(\"12/1/2022\")\n",
        "  print(df)\n",
        "\n",
        "  Args:\n",
        "      schedule_df (dataframe): the scores dataframe.\n",
        "\n",
        "  Returns:\n",
        "      ranking_df (dataframe): the dataframe of ranking statistics.\n",
        "\n",
        "  \"\"\"\n",
        "  teams = list(set(list(schedule_df[\"Home Team\"].unique()) + \n",
        "                   list(schedule_df[\"Away Team\"].unique())))\n",
        "\n",
        "  # initialize the ranking dataframe\n",
        "  ranking_df = pd.DataFrame({\n",
        "                    'Team': pd.Series(dtype='str'),\n",
        "                    'Total Points': pd.Series(dtype='int'),\n",
        "                    'Total Games': pd.Series(dtype='int'),\n",
        "                    'Total Wins': pd.Series(dtype='int'),\n",
        "                    'Total Losses': pd.Series(dtype='int'),\n",
        "                    'Total Ties': pd.Series(dtype='int'),\n",
        "                    'PPG': pd.Series(dtype='float'),})\n",
        "\n",
        "  for t in teams:\n",
        "    t_result = {'Team':t, 'Total Points': 0,\n",
        "                    'Total Games': 0,\n",
        "                    'Total Wins': 0,\n",
        "                    'Total Losses': 0,\n",
        "                    'Total Ties': 0,\n",
        "                    'PPG':0}\n",
        "    ranking_df = ranking_df.append(t_result, ignore_index=True)\n",
        "\n",
        "  # populate ranking dataframe based on schedule\n",
        "  for index,row in schedule_df.iterrows():\n",
        "    home_team = row['Home Team']\n",
        "    away_team = row['Away Team']\n",
        "    home_score = row['Home Score']\n",
        "    away_score = row['Away Score']\n",
        "\n",
        "    ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Games'] += 1\n",
        "    ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Games'] += 1\n",
        "\n",
        "    if home_score > away_score: # home win  \n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Wins'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Points'] += 3\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Losses'] += 1\n",
        "    elif home_score < away_score: # away win\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Wins'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Points'] += 3\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Losses'] += 1\n",
        "    elif home_score == away_score: # tie\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Ties'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Ties'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == home_team), 'Total Points'] += 1\n",
        "      ranking_df.loc[(ranking_df['Team'] == away_team), 'Total Points'] += 1\n",
        "\n",
        "  ranking_df['PPG'] = ranking_df['Total Points'] / ranking_df['Total Games']\n",
        "\n",
        "  ranking_df = ranking_df.sort_values(by=['PPG', 'Total Points'], \n",
        "                                      ascending=False)\n",
        "  ranking_df = ranking_df.drop_duplicates(keep='last')\n",
        "  return ranking_df\n"
      ],
      "metadata": {
        "id": "nksiVfx8w3O6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Script"
      ],
      "metadata": {
        "id": "qGqG335tPH0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demo\n",
        "df = get_scores_from_maxpreps_for_one_day(\"2/15/2023\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVlhCgezUxXt",
        "outputId": "a820048e-34c3-4686-9e18-de73774da108"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\tCentral Coast Section High School Girls Soccer Scores | 2/15/2023 Results | MaxPreps\r\n",
            "\n",
            "Found Games for 2023-02-15 00:00:00\n",
            "score not valid, using -1 instead\n",
            "score not valid, using -1 instead\n",
            "        Date      Home Team  Home Score                Away Team  Away Score\n",
            "0 2023-02-15   Presentation           1         Archbishop Mitty           4\n",
            "1 2023-02-15         Marina          -1                  Oakwood          -1\n",
            "2 2023-02-15         Harker           3  Crystal Springs Uplands           1\n",
            "3 2023-02-15         Aragon           1                  Sequoia           4\n",
            "4 2023-02-15           Gunn           1                Homestead           2\n",
            "5 2023-02-15  Saint Francis           4         Valley Christian           0\n",
            "6 2023-02-15    Santa Clara           2                 Saratoga           1\n",
            "7 2023-02-15      Los Altos           6                Palo Alto           1\n",
            "8 2023-02-15       Westmont           1                 Overfelt           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all scores\n",
        "# please note game info of previous seasons/years are not accessible,\n",
        "# only current season is accessible.\n",
        "\n",
        "# load historical data\n",
        "# scores.csv was generated between 11/10/2022 and 2/1/2023\n",
        "hist_scores = pd.read_csv('/drive/My Drive/scores.csv')\n",
        "\n",
        "start_date = date(2023, 2, 1)\n",
        "end_date = date(2023, 2, 18)\n",
        "new_scores = get_scores_from_maxpreps_for_range(start_date, end_date)\n",
        "\n",
        "scores = pd.concat([hist_scores, new_scores])\n",
        "scores['Date'] = pd.to_datetime(scores['Date'])\n",
        "scores = scores.drop_duplicates(keep='last')\n",
        "scores.to_csv('/drive/My Drive/scores_2223.csv', index=False)"
      ],
      "metadata": {
        "id": "GuJkF8RrOaut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all rankings\n",
        "rankings = get_rankings_from_scores(scores)\n",
        "rankings.to_csv('/drive/My Drive/rankings_2223.csv', index=False)"
      ],
      "metadata": {
        "id": "sah_im9Sr2a5"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}